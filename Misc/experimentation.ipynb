{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "ps = PorterStemmer()\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_rotations(word):\n",
    "    term = \"$\" + word\n",
    "    res = [term]\n",
    "    for i in range(len(word) - 1):\n",
    "        term = term[-1] + term[:-1]\n",
    "        res.append(term)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate(wildcard):\n",
    "    term = '$' + wildcard\n",
    "    for i, l in enumerate(term, 1):\n",
    "        if l == \"*\":\n",
    "            return term[i:] + term[:i-1], True\n",
    "    else:\n",
    "        return wildcard, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def union(p1, p2):\n",
    "    i = j = 0\n",
    "    res = []\n",
    "    \n",
    "    while i < len(p1) and j < len(p2):\n",
    "        if p1[i] == p2[j]:\n",
    "            res.append(p1[i])\n",
    "            i += 1\n",
    "            j += 1\n",
    "        elif p1[i] < p2[j]:\n",
    "            res.append(p1[i])\n",
    "            i += 1\n",
    "        elif p1[i] > p2[j]:\n",
    "            res.append(p2[j])\n",
    "            j += 1\n",
    "    if i < len(p1):\n",
    "        res += p1[i:]\n",
    "    else:\n",
    "        res += p2[j:]\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse(p1, total):\n",
    "    return [i for i in total if i not in p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(p1, p2):\n",
    "    i = j = 0\n",
    "    res = []\n",
    "    \n",
    "    while i < len(p1) and j < len(p2):\n",
    "        if p1[i] == p2[j]:\n",
    "            res.append(p1[i])\n",
    "            i += 1\n",
    "            j += 1\n",
    "        elif p1[i] < p2[j]:\n",
    "            i += 1\n",
    "        elif p1[i] > p2[j]:\n",
    "            j += 1\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def and_not(p1, p2):\n",
    "    i = j = 0\n",
    "    res = []\n",
    "    \n",
    "    while i < len(p1) and j < len(p2):\n",
    "        if p1[i] == p2[j]:\n",
    "            i += 1\n",
    "            j += 1\n",
    "        elif p1[i] < p2[j]:\n",
    "            res.append(p1[i])\n",
    "            i += 1\n",
    "        elif p1[i] > p2[j]:\n",
    "            j += 1\n",
    "    if i < len(p1):\n",
    "        res += p1[i:]\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def or_not(p1, p2, total):    \n",
    "    return union(p1, inverse(p2, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(term, ii):\n",
    "    if term[0] == '@':\n",
    "        return symbols[term]\n",
    "    res = []\n",
    "    rotated, is_wild = rotate(term)\n",
    "    if is_wild:\n",
    "        for w in ii.keys():\n",
    "            if len(w) >= len(term)-1:\n",
    "                for r in ii[w]['rotations']:\n",
    "                    if r[:len(rotated)] == rotated:\n",
    "                        res = union(res, ii[w]['postings'])\n",
    "                        break\n",
    "    else:\n",
    "        for w in ii.keys():\n",
    "            if w == rotated:\n",
    "                res = union(res, ii[w]['postings'])\n",
    "                break\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein_distance(word1, word2):\n",
    "    l = max(len(word1), len(word2))\n",
    "    m = np.zeros((l, l))\n",
    "    for i in range(len(word1)):\n",
    "        m[i, 0] = i\n",
    "        \n",
    "    for j in range(len(word2)):\n",
    "        m[0, j] = j\n",
    "    \n",
    "    for i in range(1, len(word1)):\n",
    "        for j in range(1, len(word2)):\n",
    "            if word1[i] == word2[j]:\n",
    "                m[i, j] = min(m[i-1, j] + 1, min(m[i, j-1] + 1, m[i-1, j-1]))\n",
    "            else:\n",
    "                m[i, j] = min(m[i-1, j] + 1, min(m[i, j-1] + 1, m[i-1, j-1] + 1))\n",
    "    return m[len(word1)-1, len(word2)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'Datasets/Shakespeare'\n",
    "ii = defaultdict(lambda: {'count': [], 'words': [], 'rotations': [], 'postings': []})\n",
    "\n",
    "id_to_txt = {}\n",
    "for i, filename in enumerate(os.listdir(directory)):\n",
    "    id_to_txt[i] = filename\n",
    "    with open(os.path.join(directory, filename), 'rt') as original:\n",
    "        sents = sent_tokenize(original.read())\n",
    "        for s in sents:\n",
    "            for w in word_tokenize(s):\n",
    "                stemmed = ps.stem(w).lower()\n",
    "                if stemmed not in stopwords.words('english'):\n",
    "                    if i not in ii[stemmed]['postings']:\n",
    "                        ii[stemmed]['postings'].append(i)\n",
    "                    if w not in ii[stemmed]['words']:\n",
    "                        ii[stemmed]['words'].append(w)\n",
    "                \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in ii.keys():\n",
    "    ii[t]['count'] = len(ii[t]['postings'])\n",
    "    \n",
    "    for w in ii[t]['words']:\n",
    "        ii[t]['rotations'] += produce_rotations(w)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('ii', np.array(dict(ii)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = np.load('ii.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match('mids*m', ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match('mid*er', ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_expr(expr, i):\n",
    "    print(\"evaluating \" + expr + \" and storing as @\" + str(i))\n",
    "    # var or not var\n",
    "    # var or var\n",
    "    # var and not var\n",
    "    # var and var\n",
    "    # var\n",
    "    # not var\n",
    "    total = [i for i in range(42)]\n",
    "    \n",
    "    keywords = [\"and\", \"or\", \"not\"]\n",
    "    expr = expr.split(\" \")\n",
    "    new_symbol = '@' + str(i)\n",
    "    \n",
    "    if expr[0] == \"not\":\n",
    "        symbols[new_symbol] = inverse(match(expr[1], ii), total)\n",
    "        return new_symbol\n",
    "        \n",
    "    else:\n",
    "        if len(expr) == 1:\n",
    "            symbols[new_symbol] = match(expr[0], ii)\n",
    "            return new_symbol\n",
    "        \n",
    "        if expr[1] == 'and':\n",
    "            if expr[2] == 'not':\n",
    "                symbols[new_symbol] = and_not(match(expr[0], ii), match(expr[3], ii))\n",
    "                return new_symbol\n",
    "            \n",
    "            else:\n",
    "                symbols[new_symbol] = intersection(match(expr[0], ii), match(expr[2], ii))\n",
    "                return new_symbol\n",
    "        \n",
    "        else:\n",
    "            if expr[2] == 'not':\n",
    "                symbols[new_symbol] = or_not(match(expr[0], ii), match(expr[3], ii), total)\n",
    "                return new_symbol\n",
    "            \n",
    "            else:\n",
    "                symbols[new_symbol] = union(match(expr[0], ii), match(expr[2], ii))\n",
    "                return new_symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_query(query):\n",
    "    stack = []\n",
    "    i = 0\n",
    "    for c in query:\n",
    "        if c != ')':\n",
    "            stack.append(c)\n",
    "        else:\n",
    "            expr = \"\"\n",
    "            while stack:\n",
    "                char = stack.pop()\n",
    "                if char != '(':\n",
    "                    expr += char\n",
    "                else:\n",
    "                    stack += list(evaluate_expr(expr[::-1], i))\n",
    "                    i += 1\n",
    "                    break\n",
    "    if stack:\n",
    "        evaluate_expr(\"\".join(stack), i)\n",
    "        i += 1\n",
    "    return symbols['@' + str(i - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = \"(mid*er and (B or not C)) or D\"\n",
    "q2 = \"not mid*er\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_query(q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_gram_index = defaultdict(lambda: set())\n",
    "for i in ii.keys():\n",
    "    for j in ii[i]['words']:\n",
    "        for k in range(len(j) - 1):\n",
    "            two_gram_index[j[k:k+2]].add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "two_gram_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"midsumer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match(word, ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for i in range(len(word) - 1):\n",
    "    res += two_gram_index[word[i:i+2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = dict(collections.Counter(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = {k: v for k, v in reversed(sorted(freqs.items(), key=lambda item: item[1]))}\n",
    "freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = defaultdict(lambda: [])\n",
    "for k, v in freqs.items():\n",
    "    ff[v].append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ed = defaultdict(lambda: [])\n",
    "for f in list(ff.keys())[:3]:\n",
    "    for w in ff[f]:\n",
    "        print(\"edit dist between \" + w + \" and \" + word + \" is \" + str(levenshtein_distance(word, w)))\n",
    "        ed[levenshtein_distance(word, w)].append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max([(ii[x]['count'], x) for x in ed[min(list(ed.keys()))]])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
